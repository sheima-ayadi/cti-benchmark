{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama \n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benchmark_existing_data.ipynb', 'benchmark_ourDatasets.ipynb', 'data', 'ourDatasets']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation for cti-mcq with llama3.1 and mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq = pd.read_csv('data/cti-mcq.tsv', sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here i'm gonna generate answer from llama3.1 and then evaluate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer(prompt):\n",
    "   return  ollama.generate(model='llama3.1', prompt=prompt)['response']\n",
    "\n",
    "new_data = dict()\n",
    "new_data['answer'] = list()\n",
    "\n",
    "limit = 100\n",
    "\n",
    "for index in range(limit):\n",
    "   prompt = mcq.iloc[index]['Prompt']\n",
    "   answer = llm_answer(prompt)\n",
    "   print(answer)\n",
    "   new_data['answer'].append(answer)\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_data, index = list(mcq.index)[:limit])\n",
    "old_df = mcq.head(limit)\n",
    "\n",
    "mcq_git = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "\n",
    "print(mcq_git.head())\n",
    "\n",
    "mcq_git.to_csv('data/generated_answer/mcq_git.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here i'm gonna generate answer from mistral and then evaluate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer(prompt):\n",
    "   return  ollama.generate(model='mistral', prompt=prompt)['response']\n",
    "\n",
    "new_data = dict()\n",
    "new_data['answer'] = list()\n",
    "\n",
    "limit = 100\n",
    "\n",
    "for index in range(limit):\n",
    "   prompt = mcq.iloc[index]['Prompt']\n",
    "   answer = llm_answer(prompt)\n",
    "   print(answer)\n",
    "   new_data['answer'].append(answer)\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_data, index = list(mcq.index)[:limit])\n",
    "old_df = mcq.head(limit)\n",
    "\n",
    "mcq_gitM = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "\n",
    "print(mcq_gitM.head())\n",
    "\n",
    "mcq_gitM.to_csv('data/generated_answer/mcq_gitM.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here i'm gonna do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"data/generated_answer/mcq_git.csv\")\n",
    "df2 = pd.read_csv('data/generated_answer/mcq_gitM.csv')\n",
    "\n",
    "def extract_predicted_option(s:str):\n",
    "    options = ['A', 'B', 'C', 'D']\n",
    "    s = s[::-1] #reverse string, find first uppercase with previous and next character not alphabetic (A*,  A , A.) ...\n",
    "    for i in range(len(s)):\n",
    "        if  s[i] in options and (True if i == 0 else not s[i-1].isalpha()) and (True if i == len(s)-1 else not s[i+1].isalpha()): \n",
    "            return s[i]\n",
    "    return \"\"\n",
    "\n",
    "def evaluate(df):\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(df)):\n",
    "        gt = df.iloc[i]['GT']\n",
    "        llm_answer = df.iloc[i]['answer']\n",
    "        predicted =  extract_predicted_option(llm_answer)\n",
    "        if predicted == gt:\n",
    "            correct_predictions+=1\n",
    "    total_predictions = len(df)\n",
    "    return correct_predictions / total_predictions * 100\n",
    "\n",
    "\n",
    "print(evaluate(df1))\n",
    "print(evaluate(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation cti-rcm with llama3.1 and mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcm = pd.read_csv('data/cti-rcm.tsv', sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first im going to generate answer from llama3.1 from the cti-rcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer(prompt):\n",
    "   return ollama.generate(model=\"llama3.1\", prompt=prompt, options={\"temperature\": 0}).get('response', \"\")\n",
    "\n",
    "new_data = dict()\n",
    "new_data['answer'] = list()\n",
    "\n",
    "limit = 100\n",
    "\n",
    "for index in range(limit):\n",
    "   prompt = rcm.iloc[index]['Prompt']\n",
    "   answer = llm_answer(prompt)\n",
    "   print(answer)\n",
    "   new_data['answer'].append(answer)\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_data, index = list(rcm.index)[:limit])\n",
    "old_df = rcm.head(limit)\n",
    "\n",
    "rcm_git = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "print(rcm_git.head())\n",
    "\n",
    "rcm_git.to_csv('data/generated_answer/rcm_git.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now im going to generate answer with mistral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer(prompt):\n",
    "   return ollama.generate(model=\"mistral\", prompt=prompt, options={\"temperature\": 0}).get('response', \"\")\n",
    "\n",
    "new_data = dict()\n",
    "new_data['answer'] = list()\n",
    "\n",
    "limit = 100\n",
    "\n",
    "for index in range(limit):\n",
    "   prompt = rcm.iloc[index]['Prompt']\n",
    "   answer = llm_answer(prompt)\n",
    "   print(answer)\n",
    "   new_data['answer'].append(answer)\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_data, index = list(rcm.index)[:limit])\n",
    "old_df = rcm.head(limit)\n",
    "\n",
    "rcm_git = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "print(rcm_git.head())\n",
    "\n",
    "rcm_git.to_csv('data/generated_answer/rcm_gitM.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now im going to do the evaluation for both mistral and llama 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rcm_git.csv: 53.0\n",
      "Accuracy for rcm_gitM.csv: 46.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the predicted CWE option from LLM response\n",
    "def extract_predicted_cwe(s: str):\n",
    "    # Example of a valid CWE pattern could be 'CWE-###' (where ### is a number)\n",
    "    if 'CWE-' in s:\n",
    "        start_idx = s.find('CWE-')\n",
    "        end_idx = start_idx + 5\n",
    "        while end_idx < len(s) and s[end_idx].isdigit():\n",
    "            end_idx += 1\n",
    "        return s[start_idx:end_idx].upper()\n",
    "    return \"\"\n",
    "\n",
    "# General function to evaluate accuracy based on Ground Truth (GT) and answers\n",
    "def evaluate(df):\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(df)):\n",
    "        gt = df.iloc[i]['GT'].upper()\n",
    "        llm_answer = df.iloc[i]['answer']\n",
    "        predicted = extract_predicted_cwe(llm_answer)\n",
    "        if predicted == gt:\n",
    "            correct_predictions += 1\n",
    "    total_predictions = len(df)\n",
    "    return correct_predictions / total_predictions * 100\n",
    "\n",
    "# Compute accuracy specifically for RCM dataset using tab-separated values (CWE format)\n",
    "def compute_rcm_accuracy(fname, col):\n",
    "    df = pd.read_csv(fname, sep='\\t')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        pred = row[col].upper()\n",
    "        gt = row['GT'].upper()\n",
    "        if pred.startswith('CWE-'):\n",
    "            total += 1\n",
    "            if pred == gt:\n",
    "                correct += 1\n",
    "        else:\n",
    "            print(f'Invalid response at row {idx + 1}')\n",
    "    return correct / total * 100\n",
    "\n",
    "# Example usage\n",
    "df1 = pd.read_csv(\"data/generated_answer/rcm_git.csv\")\n",
    "df2 = pd.read_csv(\"data/generated_answer/rcm_gitM.csv\")\n",
    "\n",
    "print(\"Accuracy for rcm_git.csv:\", evaluate(df1))\n",
    "print(\"Accuracy for rcm_gitM.csv:\", evaluate(df2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation for cti-vsp with mistral and llama 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsp = pd.read_csv('data/cti-vsp.tsv', sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first im going to generate answer from llama3.1 from the cti-rcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#function to generate model answer for vsp (change limit)\n",
    "def llm_answer(prompt):\n",
    "   return ollama.generate(model=\"llama3.1\", prompt=prompt, options={\"temperature\": 0}).get('response', \"\")\n",
    "\n",
    "\n",
    "new_data = dict()\n",
    "new_data['answer'] = list()\n",
    "start = 0\n",
    "limit = 300\n",
    "\n",
    "for index in range(start, limit):\n",
    "   prompt = vsp.iloc[index]['Prompt']\n",
    "   print(index)\n",
    "   answer = llm_answer(prompt)\n",
    "   #print(answer)\n",
    "   new_data['answer'].append(answer)\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_data, index = list(vsp.index)[:limit])\n",
    "old_df = vsp.head(limit)\n",
    "final_vsplama = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "#print(final_rcm.head())\n",
    "final_vsplama.to_csv('data/generated_answer/vsp/final_vsplama.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "#function to generate model answer for vsp (change limit)\n",
    "def llm_answer(prompt):\n",
    "   return ollama.generate(model=\"mistral\", prompt=prompt, options={\"temperature\": 0}).get('response', \"\")\n",
    "\n",
    "\n",
    "new_data = dict()\n",
    "new_data['answer'] = list()\n",
    "start = 0\n",
    "limit = 200\n",
    "\n",
    "for index in range(start, limit):\n",
    "   prompt = vsp.iloc[index]['Prompt']\n",
    "   print(index)\n",
    "   answer = llm_answer(prompt)\n",
    "   #print(answer)\n",
    "   new_data['answer'].append(answer)\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(new_data, index = list(vsp.index)[:limit])\n",
    "old_df = vsp.head(limit)\n",
    "final_vspM = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "#print(final_rcm.head())\n",
    "final_vspM.to_csv('data/generated_answer/vsp/final_vspM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'final_vspM_Vector.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "final_vsp = pd.read_csv('data/generated_answer/vsp/final_vspM.csv')\n",
    "\n",
    "# Example CVSS vector to extract\n",
    "example = \"CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\"\n",
    "\n",
    "# Initialize an empty dictionary to store the new data\n",
    "new_data = dict()\n",
    "new_data['vector'] = list()\n",
    "\n",
    "# Define limit to control how many rows to process\n",
    "limit = 200  # Modify the limit as needed\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for i in range(len(final_vsp)):\n",
    "    ans = final_vsp.iloc[i]['answer']\n",
    "    index = ans.find(\"CVSS:3.1\")  # Find the starting index of the CVSS vector\n",
    "    if index != -1:  # Ensure the vector is found\n",
    "        vector = ans[index:index+len(example)]  # Extract the vector\n",
    "    else:\n",
    "        vector = None  # Handle cases where no CVSS vector is found\n",
    "    new_data['vector'].append(vector)\n",
    "\n",
    "# Create a new DataFrame for the extracted vectors\n",
    "new_df = pd.DataFrame(new_data, index=final_vsp.index[:limit])\n",
    "\n",
    "# Select the old data (first 'limit' rows)\n",
    "old_df = final_vsp.head(limit)\n",
    "\n",
    "# Merge the old data with the new CVSS vectors\n",
    "final_vspmistral = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "final_vspmistral.to_csv('data/generated_answer/vsp/final_vspM_Vector.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'final_vspM_Vector.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvss in c:\\users\\cheim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvss\n",
    "from cvss import CVSS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cvss_score(cvss_vector):\n",
    "    c = CVSS3(cvss_vector)\n",
    "    cvss_score = c.scores()[0]\n",
    "    return cvss_score\n",
    "\n",
    "def compute_vsp_mad(fname, col):\n",
    "    cvss_prefix = ''   # should be empty string if the model responds with the prefix\n",
    "    #df = pd.read_csv(fname, sep='\\t')\n",
    "    df = final_vspmistral\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        pred = row[col].upper()\n",
    "        gt = row['GT'].upper()\n",
    "        try:\n",
    "            pred_vector = cvss_prefix + pred\n",
    "            pred_score = get_cvss_score(pred_vector)\n",
    "            gt_score = get_cvss_score(gt)\n",
    "            print(pred_score, gt_score)\n",
    "            print(abs(pred_score-gt_score))\n",
    "            error += abs(pred_score-gt_score)\n",
    "        except Exception as e:\n",
    "            print('Invalid response at row {}'.format(idx+1))\n",
    "            print(e)\n",
    "            continue\n",
    "        total += 1\n",
    "    print(error)\n",
    "    return error/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2 5.5\n",
      "1.7000000000000002\n",
      "7.2 8.1\n",
      "0.8999999999999995\n",
      "10.0 5.4\n",
      "4.6\n",
      "8.4 7.8\n",
      "0.6000000000000005\n",
      "9.1 5.4\n",
      "3.6999999999999993\n",
      "10.0 5.4\n",
      "4.6\n",
      "8.2 7.8\n",
      "0.39999999999999947\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "8.8 6.1\n",
      "2.700000000000001\n",
      "7.5 5.5\n",
      "2.0\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "10.0 7.8\n",
      "2.2\n",
      "7.5 4.4\n",
      "3.0999999999999996\n",
      "8.3 8.8\n",
      "0.5\n",
      "6.7 7.8\n",
      "1.0999999999999996\n",
      "10.0 7.5\n",
      "2.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "9.6 6.1\n",
      "3.5\n",
      "9.6 9.8\n",
      "0.20000000000000107\n",
      "9.8 7.2\n",
      "2.6000000000000005\n",
      "10.0 5.4\n",
      "4.6\n",
      "10.0 7.5\n",
      "2.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.1 6.1\n",
      "3.0\n",
      "10.0 7.5\n",
      "2.5\n",
      "9.8 9.1\n",
      "0.7000000000000011\n",
      "10.0 6.5\n",
      "3.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.1 5.3\n",
      "3.8\n",
      "9.1 6.5\n",
      "2.5999999999999996\n",
      "8.3 9.8\n",
      "1.5\n",
      "9.8 7.5\n",
      "2.3000000000000007\n",
      "9.8 5.5\n",
      "4.300000000000001\n",
      "7.2 7.8\n",
      "0.5999999999999996\n",
      "9.8 5.5\n",
      "4.300000000000001\n",
      "8.8 5.4\n",
      "3.4000000000000004\n",
      "9.8 5.3\n",
      "4.500000000000001\n",
      "10.0 3.3\n",
      "6.7\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "7.5 7.5\n",
      "0.0\n",
      "7.2 5.5\n",
      "1.7000000000000002\n",
      "9.6 9.8\n",
      "0.20000000000000107\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "7.2 9.8\n",
      "2.6000000000000005\n",
      "8.4 7.8\n",
      "0.6000000000000005\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "9.8 6.5\n",
      "3.3000000000000007\n",
      "9.1 7.8\n",
      "1.2999999999999998\n",
      "8.3 8.8\n",
      "0.5\n",
      "8.2 4.4\n",
      "3.799999999999999\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "8.3 6.1\n",
      "2.200000000000001\n",
      "8.3 7.8\n",
      "0.5000000000000009\n",
      "9.6 6.1\n",
      "3.5\n",
      "9.6 6.1\n",
      "3.5\n",
      "8.2 6.7\n",
      "1.4999999999999991\n",
      "9.6 5.4\n",
      "4.199999999999999\n",
      "7.2 5.5\n",
      "1.7000000000000002\n",
      "9.3 5.5\n",
      "3.8000000000000007\n",
      "10.0 5.3\n",
      "4.7\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "8.1 5.4\n",
      "2.6999999999999993\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "8.3 9.8\n",
      "1.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.1 7.5\n",
      "1.5999999999999996\n",
      "9.8 6.1\n",
      "3.700000000000001\n",
      "9.8 5.5\n",
      "4.300000000000001\n",
      "8.1 7.5\n",
      "0.5999999999999996\n",
      "9.8 6.1\n",
      "3.700000000000001\n",
      "9.8 5.4\n",
      "4.4\n",
      "8.7 5.4\n",
      "3.299999999999999\n",
      "7.8 7.8\n",
      "0.0\n",
      "7.5 7.5\n",
      "0.0\n",
      "6.5 5.3\n",
      "1.2000000000000002\n",
      "6.2 5.5\n",
      "0.7000000000000002\n",
      "8.6 8.8\n",
      "0.20000000000000107\n",
      "8.4 7.1\n",
      "1.3000000000000007\n",
      "8.3 9.1\n",
      "0.7999999999999989\n",
      "7.5 7.5\n",
      "0.0\n",
      "7.4 5.5\n",
      "1.9000000000000004\n",
      "8.8 5.4\n",
      "3.4000000000000004\n",
      "9.1 5.4\n",
      "3.6999999999999993\n",
      "8.8 7.8\n",
      "1.0000000000000009\n",
      "10.0 9.1\n",
      "0.9000000000000004\n",
      "8.0 9.8\n",
      "1.8000000000000007\n",
      "10.0 4.3\n",
      "5.7\n",
      "8.3 7.8\n",
      "0.5000000000000009\n",
      "8.0 6.1\n",
      "1.9000000000000004\n",
      "8.5 5.5\n",
      "3.0\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "10.0 5.4\n",
      "4.6\n",
      "10.0 7.5\n",
      "2.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.8 5.5\n",
      "4.300000000000001\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "9.8 5.5\n",
      "4.300000000000001\n",
      "8.8 7.8\n",
      "1.0000000000000009\n",
      "9.0 7.5\n",
      "1.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.8 5.4\n",
      "4.4\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "9.8 5.3\n",
      "4.500000000000001\n",
      "9.6 6.1\n",
      "3.5\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "10.0 5.5\n",
      "4.5\n",
      "9.0 8.8\n",
      "0.1999999999999993\n",
      "10.0 4.8\n",
      "5.2\n",
      "9.8 8.8\n",
      "1.0\n",
      "7.5 4.4\n",
      "3.0999999999999996\n",
      "8.4 8.1\n",
      "0.3000000000000007\n",
      "9.8 6.1\n",
      "3.700000000000001\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.1 7.0\n",
      "2.0999999999999996\n",
      "9.1 4.8\n",
      "4.3\n",
      "9.1 8.8\n",
      "0.29999999999999893\n",
      "10.0 6.3\n",
      "3.7\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.3 5.5\n",
      "3.8000000000000007\n",
      "9.8 8.2\n",
      "1.6000000000000014\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "7.2 7.8\n",
      "0.5999999999999996\n",
      "9.1 4.8\n",
      "4.3\n",
      "9.8 9.8\n",
      "0.0\n",
      "6.0 7.8\n",
      "1.7999999999999998\n",
      "7.2 9.8\n",
      "2.6000000000000005\n",
      "9.1 5.4\n",
      "3.6999999999999993\n",
      "5.9 7.5\n",
      "1.5999999999999996\n",
      "9.8 4.8\n",
      "5.000000000000001\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.4 7.8\n",
      "0.6000000000000005\n",
      "2.0 4.8\n",
      "2.8\n",
      "9.6 6.1\n",
      "3.5\n",
      "9.1 4.8\n",
      "4.3\n",
      "10.0 6.5\n",
      "3.5\n",
      "9.1 7.2\n",
      "1.8999999999999995\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "10.0 6.5\n",
      "3.5\n",
      "9.8 7.5\n",
      "2.3000000000000007\n",
      "10.0 9.9\n",
      "0.09999999999999964\n",
      "10.0 5.4\n",
      "4.6\n",
      "9.8 7.5\n",
      "2.3000000000000007\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.1 5.4\n",
      "2.6999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.0 6.5\n",
      "2.5\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "9.8 3.3\n",
      "6.500000000000001\n",
      "9.0 7.5\n",
      "1.5\n",
      "9.0 9.8\n",
      "0.8000000000000007\n",
      "9.8 6.5\n",
      "3.3000000000000007\n",
      "9.6 6.1\n",
      "3.5\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.8 6.5\n",
      "3.3000000000000007\n",
      "8.2 7.8\n",
      "0.39999999999999947\n",
      "7.2 9.8\n",
      "2.6000000000000005\n",
      "9.4 5.4\n",
      "4.0\n",
      "Invalid response at row 168\n",
      "Unknown value \"[L OR\" in field \"I:[L OR\"\n",
      "9.0 8.8\n",
      "0.1999999999999993\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "9.4 5.3\n",
      "4.1000000000000005\n",
      "9.0 5.9\n",
      "3.0999999999999996\n",
      "7.2 7.8\n",
      "0.5999999999999996\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "8.6 5.3\n",
      "3.3\n",
      "7.5 8.6\n",
      "1.0999999999999996\n",
      "9.1 8.8\n",
      "0.29999999999999893\n",
      "9.4 5.5\n",
      "3.9000000000000004\n",
      "9.8 7.5\n",
      "2.3000000000000007\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.6 4.8\n",
      "4.8\n",
      "8.8 6.1\n",
      "2.700000000000001\n",
      "10.0 4.8\n",
      "5.2\n",
      "8.0 7.8\n",
      "0.20000000000000018\n",
      "2.0 4.8\n",
      "2.8\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "10.0 8.2\n",
      "1.8000000000000007\n",
      "8.3 9.8\n",
      "1.5\n",
      "9.6 6.1\n",
      "3.5\n",
      "8.4 8.8\n",
      "0.40000000000000036\n",
      "9.6 7.8\n",
      "1.7999999999999998\n",
      "9.8 6.1\n",
      "3.700000000000001\n",
      "9.8 8.8\n",
      "1.0\n",
      "Invalid response at row 194\n",
      "Unknown value \"A\" in field \"PR:A\"\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "9.1 5.5\n",
      "3.5999999999999996\n",
      "9.6 9.8\n",
      "0.20000000000000107\n",
      "9.6 5.4\n",
      "4.199999999999999\n",
      "10.0 7.5\n",
      "2.5\n",
      "10.0 4.7\n",
      "5.3\n",
      "427.70000000000016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1601010101010107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_vsp_mad(\"\", col = \"vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation for vsp lama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'final_vspL_vector' has been created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "final_vsp = pd.read_csv('data/generated_answer/vsp/final_vsplama.csv')\n",
    "\n",
    "# Example CVSS vector to extract\n",
    "example = \"CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\"\n",
    "\n",
    "# Initialize an empty dictionary to store the new data\n",
    "new_data = dict()\n",
    "new_data['vector'] = list()\n",
    "\n",
    "# Define limit to control how many rows to process\n",
    "limit = 300  # Modify the limit as needed\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for i in range(len(final_vsp)):\n",
    "    ans = final_vsp.iloc[i]['answer']\n",
    "    index = ans.find(\"CVSS:3.1\")  # Find the starting index of the CVSS vector\n",
    "    if index != -1:  # Ensure the vector is found\n",
    "        vector = ans[index:index+len(example)]  # Extract the vector\n",
    "    else:\n",
    "        vector = None  # Handle cases where no CVSS vector is found\n",
    "    new_data['vector'].append(vector)\n",
    "\n",
    "# Create a new DataFrame for the extracted vectors\n",
    "new_df = pd.DataFrame(new_data, index=final_vsp.index[:limit])\n",
    "\n",
    "# Select the old data (first 'limit' rows)\n",
    "old_df = final_vsp.head(limit)\n",
    "\n",
    "# Merge the old data with the new CVSS vectors\n",
    "final_vspllama = pd.merge(old_df, new_df, left_index=True, right_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "final_vspllama.to_csv('data/generated_answer/vsp/final_vspL_vector.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'final_vspL_vector' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cvss_score(cvss_vector):\n",
    "    c = CVSS3(cvss_vector)\n",
    "    cvss_score = c.scores()[0]\n",
    "    return cvss_score\n",
    "\n",
    "def compute_vsp_madlama(fname, col):\n",
    "    cvss_prefix = ''   # should be empty string if the model responds with the prefix\n",
    "    #df = pd.read_csv(fname, sep='\\t')\n",
    "    df = final_vspllama\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        pred = row[col].upper()\n",
    "        gt = row['GT'].upper()\n",
    "        try:\n",
    "            pred_vector = cvss_prefix + pred\n",
    "            pred_score = get_cvss_score(pred_vector)\n",
    "            gt_score = get_cvss_score(gt)\n",
    "            print(pred_score, gt_score)\n",
    "            print(abs(pred_score-gt_score))\n",
    "            error += abs(pred_score-gt_score)\n",
    "        except Exception as e:\n",
    "            print('Invalid response at row {}'.format(idx+1))\n",
    "            print(e)\n",
    "            continue\n",
    "        total += 1\n",
    "    print(error)\n",
    "    return error/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.8 5.5\n",
      "4.300000000000001\n",
      "4.3 8.1\n",
      "3.8\n",
      "8.6 5.4\n",
      "3.1999999999999993\n",
      "7.7 7.8\n",
      "0.09999999999999964\n",
      "10.0 5.4\n",
      "4.6\n",
      "5.4 5.4\n",
      "0.0\n",
      "0.0 7.8\n",
      "7.8\n",
      "6.5 9.8\n",
      "3.3000000000000007\n",
      "6.5 6.1\n",
      "0.40000000000000036\n",
      "7.5 5.5\n",
      "2.0\n",
      "8.1 6.1\n",
      "2.0\n",
      "9.6 7.8\n",
      "1.7999999999999998\n",
      "4.4 4.4\n",
      "0.0\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "6.8 7.8\n",
      "1.0\n",
      "7.5 7.5\n",
      "0.0\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.6 9.8\n",
      "1.200000000000001\n",
      "7.3 9.8\n",
      "2.500000000000001\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "9.6 9.8\n",
      "0.20000000000000107\n",
      "8.8 7.2\n",
      "1.6000000000000005\n",
      "9.8 5.4\n",
      "4.4\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "8.6 9.8\n",
      "1.200000000000001\n",
      "9.4 6.1\n",
      "3.3000000000000007\n",
      "9.4 7.5\n",
      "1.9000000000000004\n",
      "10.0 9.1\n",
      "0.9000000000000004\n",
      "8.6 6.5\n",
      "2.0999999999999996\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.3 5.3\n",
      "4.000000000000001\n",
      "9.4 6.5\n",
      "2.9000000000000004\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "7.5 7.5\n",
      "0.0\n",
      "8.2 5.5\n",
      "2.6999999999999993\n",
      "8.4 7.8\n",
      "0.6000000000000005\n",
      "8.2 5.5\n",
      "2.6999999999999993\n",
      "7.2 5.4\n",
      "1.7999999999999998\n",
      "8.2 5.3\n",
      "2.8999999999999995\n",
      "5.8 3.3\n",
      "2.5\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.8 7.5\n",
      "1.3000000000000007\n",
      "8.6 5.5\n",
      "3.0999999999999996\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.8 9.8\n",
      "1.0\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.2 7.8\n",
      "0.39999999999999947\n",
      "8.6 8.8\n",
      "0.20000000000000107\n",
      "7.5 7.5\n",
      "0.0\n",
      "9.3 6.5\n",
      "2.8000000000000007\n",
      "9.8 7.8\n",
      "2.000000000000001\n",
      "8.3 8.8\n",
      "0.5\n",
      "4.8 4.4\n",
      "0.39999999999999947\n",
      "9.4 6.1\n",
      "3.3000000000000007\n",
      "6.3 6.1\n",
      "0.20000000000000018\n",
      "9.8 7.8\n",
      "2.000000000000001\n",
      "6.5 6.1\n",
      "0.40000000000000036\n",
      "4.3 6.1\n",
      "1.7999999999999998\n",
      "0.0 6.7\n",
      "6.7\n",
      "9.3 5.4\n",
      "3.9000000000000004\n",
      "9.9 5.5\n",
      "4.4\n",
      "4.3 5.5\n",
      "1.2000000000000002\n",
      "8.1 5.3\n",
      "2.8\n",
      "8.2 6.1\n",
      "2.0999999999999996\n",
      "9.4 5.4\n",
      "4.0\n",
      "9.8 9.8\n",
      "0.0\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "7.5 7.5\n",
      "0.0\n",
      "9.6 6.1\n",
      "3.5\n",
      "7.2 5.5\n",
      "1.7000000000000002\n",
      "7.3 7.5\n",
      "0.20000000000000018\n",
      "9.1 6.1\n",
      "3.0\n",
      "10.0 5.4\n",
      "4.6\n",
      "9.1 5.4\n",
      "3.6999999999999993\n",
      "9.0 7.8\n",
      "1.2000000000000002\n",
      "9.3 7.5\n",
      "1.8000000000000007\n",
      "4.4 5.3\n",
      "0.8999999999999995\n",
      "8.4 5.5\n",
      "2.9000000000000004\n",
      "9.3 8.8\n",
      "0.5\n",
      "5.1 7.1\n",
      "2.0\n",
      "9.4 9.1\n",
      "0.3000000000000007\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "7.1 5.5\n",
      "1.5999999999999996\n",
      "10.0 5.4\n",
      "4.6\n",
      "6.7 5.4\n",
      "1.2999999999999998\n",
      "7.8 7.8\n",
      "0.0\n",
      "9.8 9.1\n",
      "0.7000000000000011\n",
      "8.2 9.8\n",
      "1.6000000000000014\n",
      "9.1 4.3\n",
      "4.8\n",
      "8.8 7.8\n",
      "1.0000000000000009\n",
      "9.8 6.1\n",
      "3.700000000000001\n",
      "7.0 5.5\n",
      "1.5\n",
      "9.8 9.8\n",
      "0.0\n",
      "4.1 5.4\n",
      "1.3000000000000007\n",
      "8.2 7.5\n",
      "0.6999999999999993\n",
      "8.6 9.8\n",
      "1.200000000000001\n",
      "Invalid response at row 101\n",
      "Unknown value \"M\" in field \"C:M\"\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.6 5.5\n",
      "3.0999999999999996\n",
      "9.6 7.8\n",
      "1.7999999999999998\n",
      "7.5 7.5\n",
      "0.0\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.8 5.4\n",
      "4.4\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.8 5.3\n",
      "4.500000000000001\n",
      "7.1 6.1\n",
      "1.0\n",
      "8.6 9.8\n",
      "1.200000000000001\n",
      "9.8 5.5\n",
      "4.300000000000001\n",
      "9.8 8.8\n",
      "1.0\n",
      "5.3 4.8\n",
      "0.5\n",
      "8.8 8.8\n",
      "0.0\n",
      "6.7 4.4\n",
      "2.3\n",
      "8.4 8.1\n",
      "0.3000000000000007\n",
      "9.8 6.1\n",
      "3.700000000000001\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.9 9.8\n",
      "0.09999999999999964\n",
      "10.0 7.0\n",
      "3.0\n",
      "2.3 4.8\n",
      "2.5\n",
      "9.4 8.8\n",
      "0.5999999999999996\n",
      "10.0 6.3\n",
      "3.7\n",
      "7.5 9.8\n",
      "2.3000000000000007\n",
      "8.0 5.5\n",
      "2.5\n",
      "10.0 8.2\n",
      "1.8000000000000007\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 7.8\n",
      "2.2\n",
      "6.8 4.8\n",
      "2.0\n",
      "8.3 9.8\n",
      "1.5\n",
      "7.7 7.8\n",
      "0.09999999999999964\n",
      "9.4 9.8\n",
      "0.40000000000000036\n",
      "7.6 5.4\n",
      "2.1999999999999993\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "8.2 4.8\n",
      "3.3999999999999995\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "8.4 7.8\n",
      "0.6000000000000005\n",
      "2.4 4.8\n",
      "2.4\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "6.4 4.8\n",
      "1.6000000000000005\n",
      "9.3 6.5\n",
      "2.8000000000000007\n",
      "7.2 7.2\n",
      "0.0\n",
      "9.3 7.5\n",
      "1.8000000000000007\n",
      "10.0 6.5\n",
      "3.5\n",
      "8.2 7.5\n",
      "0.6999999999999993\n",
      "9.3 9.9\n",
      "0.5999999999999996\n",
      "9.1 5.4\n",
      "3.6999999999999993\n",
      "6.1 7.5\n",
      "1.4000000000000004\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.6 5.4\n",
      "4.199999999999999\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "8.3 6.5\n",
      "1.8000000000000007\n",
      "6.3 8.8\n",
      "2.500000000000001\n",
      "8.8 3.3\n",
      "5.500000000000001\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "7.5 6.5\n",
      "1.0\n",
      "7.4 6.1\n",
      "1.3000000000000007\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.8 9.8\n",
      "0.0\n",
      "5.3 6.5\n",
      "1.2000000000000002\n",
      "8.4 7.8\n",
      "0.6000000000000005\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "5.3 5.4\n",
      "0.10000000000000053\n",
      "8.2 7.5\n",
      "0.6999999999999993\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "9.8 9.8\n",
      "0.0\n",
      "7.6 5.3\n",
      "2.3\n",
      "6.3 5.9\n",
      "0.39999999999999947\n",
      "4.7 7.8\n",
      "3.0999999999999996\n",
      "9.6 6.1\n",
      "3.5\n",
      "8.6 5.3\n",
      "3.3\n",
      "9.3 8.6\n",
      "0.7000000000000011\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "5.3 5.5\n",
      "0.20000000000000018\n",
      "8.6 7.5\n",
      "1.0999999999999996\n",
      "9.1 9.8\n",
      "0.7000000000000011\n",
      "8.8 4.8\n",
      "4.000000000000001\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "10.0 4.8\n",
      "5.2\n",
      "10.0 7.8\n",
      "2.2\n",
      "2.2 4.8\n",
      "2.5999999999999996\n",
      "8.1 8.8\n",
      "0.7000000000000011\n",
      "9.3 8.2\n",
      "1.1000000000000014\n",
      "9.8 9.8\n",
      "0.0\n",
      "6.5 6.1\n",
      "0.40000000000000036\n",
      "5.4 8.8\n",
      "3.4000000000000004\n",
      "10.0 7.8\n",
      "2.2\n",
      "10.0 6.1\n",
      "3.9000000000000004\n",
      "9.8 8.8\n",
      "1.0\n",
      "9.9 5.4\n",
      "4.5\n",
      "5.3 6.1\n",
      "0.7999999999999998\n",
      "7.3 5.5\n",
      "1.7999999999999998\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.4 5.4\n",
      "4.0\n",
      "9.9 7.5\n",
      "2.4000000000000004\n",
      "10.0 4.7\n",
      "5.3\n",
      "7.6 5.4\n",
      "2.1999999999999993\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.3 5.4\n",
      "2.9000000000000004\n",
      "10.0 7.2\n",
      "2.8\n",
      "4.0 5.5\n",
      "1.5\n",
      "7.3 4.8\n",
      "2.5\n",
      "10.0 5.4\n",
      "4.6\n",
      "6.1 7.8\n",
      "1.7000000000000002\n",
      "8.7 4.8\n",
      "3.8999999999999995\n",
      "10.0 6.5\n",
      "3.5\n",
      "5.6 5.4\n",
      "0.1999999999999993\n",
      "9.3 7.5\n",
      "1.8000000000000007\n",
      "10.0 9.6\n",
      "0.40000000000000036\n",
      "8.4 5.4\n",
      "3.0\n",
      "9.4 5.4\n",
      "4.0\n",
      "6.3 5.4\n",
      "0.8999999999999995\n",
      "8.9 5.5\n",
      "3.4000000000000004\n",
      "9.8 9.8\n",
      "0.0\n",
      "7.6 6.1\n",
      "1.5\n",
      "7.9 5.4\n",
      "2.5\n",
      "8.4 7.0\n",
      "1.4000000000000004\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.6 4.3\n",
      "4.3\n",
      "10.0 7.5\n",
      "2.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.3 7.5\n",
      "1.8000000000000007\n",
      "8.8 6.1\n",
      "2.700000000000001\n",
      "7.6 6.1\n",
      "1.5\n",
      "7.1 4.9\n",
      "2.1999999999999993\n",
      "6.7 4.8\n",
      "1.9000000000000004\n",
      "9.8 7.8\n",
      "2.000000000000001\n",
      "7.5 6.5\n",
      "1.0\n",
      "8.8 8.8\n",
      "0.0\n",
      "9.4 7.5\n",
      "1.9000000000000004\n",
      "6.7 7.1\n",
      "0.39999999999999947\n",
      "8.8 9.8\n",
      "1.0\n",
      "9.4 9.8\n",
      "0.40000000000000036\n",
      "9.9 9.8\n",
      "0.09999999999999964\n",
      "9.4 5.4\n",
      "4.0\n",
      "6.3 5.4\n",
      "0.8999999999999995\n",
      "9.6 9.8\n",
      "0.20000000000000107\n",
      "7.5 5.3\n",
      "2.2\n",
      "4.2 6.7\n",
      "2.5\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.6 8.8\n",
      "0.7999999999999989\n",
      "7.5 9.8\n",
      "2.3000000000000007\n",
      "8.6 7.8\n",
      "0.7999999999999998\n",
      "9.8 7.8\n",
      "2.000000000000001\n",
      "9.9 7.5\n",
      "2.4000000000000004\n",
      "9.3 5.4\n",
      "3.9000000000000004\n",
      "9.3 7.2\n",
      "2.1000000000000005\n",
      "7.2 7.5\n",
      "0.2999999999999998\n",
      "7.5 7.5\n",
      "0.0\n",
      "5.5 5.3\n",
      "0.20000000000000018\n",
      "5.3 4.3\n",
      "1.0\n",
      "10.0 7.5\n",
      "2.5\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.9 9.8\n",
      "0.09999999999999964\n",
      "8.8 5.4\n",
      "3.4000000000000004\n",
      "7.5 7.5\n",
      "0.0\n",
      "9.1 4.8\n",
      "4.3\n",
      "7.5 6.1\n",
      "1.4000000000000004\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "9.8 9.8\n",
      "0.0\n",
      "9.4 9.8\n",
      "0.40000000000000036\n",
      "9.0 4.8\n",
      "4.2\n",
      "9.9 4.1\n",
      "5.800000000000001\n",
      "10.0 8.8\n",
      "1.1999999999999993\n",
      "10.0 7.5\n",
      "2.5\n",
      "9.6 6.1\n",
      "3.5\n",
      "8.5 9.8\n",
      "1.3000000000000007\n",
      "7.5 6.5\n",
      "1.0\n",
      "9.8 9.8\n",
      "0.0\n",
      "10.0 8.1\n",
      "1.9000000000000004\n",
      "10.0 9.8\n",
      "0.1999999999999993\n",
      "9.1 8.8\n",
      "0.29999999999999893\n",
      "7.8 7.8\n",
      "0.0\n",
      "10.0 6.5\n",
      "3.5\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.3 5.4\n",
      "2.9000000000000004\n",
      "10.0 7.5\n",
      "2.5\n",
      "9.0 7.2\n",
      "1.7999999999999998\n",
      "9.8 9.8\n",
      "0.0\n",
      "8.8 5.5\n",
      "3.3000000000000007\n",
      "8.6 5.4\n",
      "3.1999999999999993\n",
      "8.1 7.2\n",
      "0.8999999999999995\n",
      "9.8 7.2\n",
      "2.6000000000000005\n",
      "10.0 8.3\n",
      "1.6999999999999993\n",
      "4.7 7.1\n",
      "2.3999999999999995\n",
      "5.5 5.5\n",
      "0.0\n",
      "9.8 5.4\n",
      "4.4\n",
      "7.5 4.9\n",
      "2.5999999999999996\n",
      "7.5 9.8\n",
      "2.3000000000000007\n",
      "8.6 6.1\n",
      "2.5\n",
      "8.8 3.7\n",
      "5.1000000000000005\n",
      "9.8 8.8\n",
      "1.0\n",
      "7.5 5.3\n",
      "2.2\n",
      "7.1 5.4\n",
      "1.6999999999999993\n",
      "8.6 5.4\n",
      "3.1999999999999993\n",
      "8.8 8.1\n",
      "0.7000000000000011\n",
      "527.1999999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.763210702341136"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_vsp_madlama(\"\", col = \"vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation of the summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid response at row 101: Unknown value \"M\" in field \"C:M\"\n",
      "Invalid response at row 168: Unknown value \"[L OR\" in field \"I:[L OR\"\n",
      "Invalid response at row 194: Unknown value \"A\" in field \"PR:A\"\n",
      "Les résultats des évaluations ont été enregistrés dans 'evaluation_summary.csv'.\n",
      "     Model  MCQ Accuracy (%)  RCM Accuracy (%)  \\\n",
      "0    LLaMA              36.0               0.0   \n",
      "1  Mistral              44.0               0.0   \n",
      "\n",
      "   VSP MAD (Mean Absolute Difference)  \n",
      "0                            1.763211  \n",
      "1                            2.160101  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from cvss import CVSS3\n",
    "\n",
    "# Chargement des fichiers d'évaluation\n",
    "mcq_llama = pd.read_csv('data/generated_answer/mcq_git.csv')\n",
    "mcq_mistral = pd.read_csv('data/generated_answer/mcq_gitM.csv')\n",
    "rcm_llama = pd.read_csv('data/generated_answer/rcm_git.csv')\n",
    "rcm_mistral = pd.read_csv('data/generated_answer/rcm_gitM.csv')\n",
    "vsp_llama = pd.read_csv('data/generated_answer/vsp/final_vspL_vector.csv')\n",
    "vsp_mistral = pd.read_csv('data/generated_answer/vsp/final_vspM_Vector.csv')\n",
    "\n",
    "# Fonction evaluate pour les évaluations MCQ\n",
    "def evaluate(df):\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(df)):\n",
    "        gt = df.iloc[i]['GT']\n",
    "        llm_answer = df.iloc[i]['answer']\n",
    "        predicted = extract_predicted_option(llm_answer)\n",
    "        if predicted == gt:\n",
    "            correct_predictions += 1\n",
    "    total_predictions = len(df)\n",
    "    return correct_predictions / total_predictions * 100\n",
    "\n",
    "# Fonction extract_predicted_option pour extraire la réponse prédite\n",
    "def extract_predicted_option(s: str):\n",
    "    options = ['A', 'B', 'C', 'D']\n",
    "    s = s[::-1]  # Inverse la chaîne pour trouver la première lettre\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in options and (i == 0 or not s[i - 1].isalpha()) and (i == len(s) - 1 or not s[i + 1].isalpha()):\n",
    "            return s[i]\n",
    "    return \"\"\n",
    "\n",
    "# Calcul des scores pour chaque évaluation MCQ\n",
    "mcq_llama_accuracy = evaluate(mcq_llama)\n",
    "mcq_mistral_accuracy = evaluate(mcq_mistral)\n",
    "\n",
    "# Calcul des scores pour les RCM en comparant les réponses avec la vérité terrain\n",
    "rcm_llama_accuracy = (rcm_llama['answer'] == rcm_llama['GT']).mean() * 100\n",
    "rcm_mistral_accuracy = (rcm_mistral['answer'] == rcm_mistral['GT']).mean() * 100\n",
    "\n",
    "# Fonction get_cvss_score (déjà définie dans votre code)\n",
    "def get_cvss_score(cvss_vector):\n",
    "    c = CVSS3(cvss_vector)\n",
    "    return c.scores()[0]\n",
    "\n",
    "# Calcul des MAD pour VSP\n",
    "def compute_vsp_madlama(fname, col='vector'):\n",
    "    df = vsp_llama\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        pred = row[col].upper()  # Vecteur prédictif\n",
    "        gt = row['GT'].upper()  # Vecteur attendu\n",
    "        try:\n",
    "            pred_score = get_cvss_score(pred)\n",
    "            gt_score = get_cvss_score(gt)\n",
    "            error += abs(pred_score - gt_score)\n",
    "        except Exception as e:\n",
    "            print(f'Invalid response at row {idx+1}: {e}')\n",
    "            continue\n",
    "        total += 1\n",
    "    return error / total\n",
    "\n",
    "def compute_vsp_mad(fname, col='vector'):\n",
    "    df = vsp_mistral\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        pred = row[col].upper()\n",
    "        gt = row['GT'].upper()\n",
    "        try:\n",
    "            pred_score = get_cvss_score(pred)\n",
    "            gt_score = get_cvss_score(gt)\n",
    "            error += abs(pred_score - gt_score)\n",
    "        except Exception as e:\n",
    "            print(f'Invalid response at row {idx+1}: {e}')\n",
    "            continue\n",
    "        total += 1\n",
    "    return error / total\n",
    "\n",
    "# Calcul des MAD pour VSP\n",
    "vsp_llama_mad = compute_vsp_madlama(\"\")\n",
    "vsp_mistral_mad = compute_vsp_mad(\"\")\n",
    "\n",
    "# Création d'un DataFrame pour résumer les résultats\n",
    "results = {\n",
    "    \"Model\": [\"LLaMA\", \"Mistral\"],\n",
    "    \"MCQ Accuracy (%)\": [mcq_llama_accuracy, mcq_mistral_accuracy],\n",
    "    \"RCM Accuracy (%)\": [rcm_llama_accuracy, rcm_mistral_accuracy],\n",
    "    \"VSP MAD (Mean Absolute Difference)\": [vsp_llama_mad, vsp_mistral_mad]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "\n",
    "# Sauvegarde des résultats dans un fichier CSV\n",
    "summary_df.to_csv('evaluation_summary.csv', index=False)\n",
    "\n",
    "print(\"Les résultats des évaluations ont été enregistrés dans 'evaluation_summary.csv'.\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['URL', 'Description', 'Prompt', 'GT', 'answer', 'vector'], dtype='object')\n",
      "Index(['URL', 'Description', 'Prompt', 'GT', 'answer', 'vector'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vsp_llama.columns)\n",
    "print(vsp_mistral.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
